# Ollama是什么?

Ollama 不是一个大语言模型, 它只是一个允许大模型的脚手架。

Ollama 是一个强大的框架，设计用于在 Docker 容器中部署 LLM。

Ollama 的主要功能是在 Docker 容器内部署和管理 LLM 的促进者，它使该过程变得非常简单。

它帮助用户快速在本地运行大模型，通过简单的安装指令，可以让用户执行一条命令就在本地运行开源大型语言模型。

## Ollama有两种模式

- CPU模式
- GPU显卡模式

> 这里使用的是CPU模式, GPU模式请自行百度

## 安装

```sh
docker pull luode0320/ollama:latest
```

## 启动

- 启动后只是启动了一个脚手架, 并没有启用任何的模型
- 需要我们进入ollama后安装我们需要的大模型

```sh
docker run -d \
--restart=always  \
-p 11434:11434 \
--name ollama \
-v /usr/local/src/ollama:/root/.ollama \
--name ollama \
luode0320/ollama:latest
```

```sh
docker exec -it ollama ollama --version
# ollama version is 0.1.38
```

# 安装模型

3B模型需要8G内存，7B 至少需要 8GB 内存，运行 13B 至少需要 16GB 内存。

[模型仓库](https://ollama.com/library)

- 下面的命令就是允许大模型了, 如果没有下载会先下载

```
docker exec -it ollama ollama run gemma:2b
```

```sh
[root@luode ~]# docker exec -it ollama ollama run gemma:2b
success
>>> 你好
你好！有什么我可以帮助你的吗？
```

- 其他命令

```sh
docker exec -it ollama ollama list # 查看安装的模型
docker exec -it ollama ollama rm <name> # 删除模型
```

