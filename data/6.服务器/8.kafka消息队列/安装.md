## 创建目录

```sh
mkdir -p /usr/local/src/kafka/data
# 权限和容器的权限必须一致, 否则无法挂载
chown -R 1001:1001 /usr/local/src/kafka/data
# 权限和容器的权限必须一致, 否则无法挂载
chmod -R 775 /usr/local/src/kafka/data
```



# 启动

```sh
docker run -d \
  --restart=always \
  --name kafka \
  -e KAFKA_CFG_NODE_ID=1 \
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.2.20:9092 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@0.0.0.0:9093 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv \
  -e KAFKA_CFG_LOG_RETENTION_BYTES=536870912 \
  -e KAFKA_CFG_LOG_SEGMENT_BYTES=104857600 \
  -e KAFKA_LOG_DIRS=/bitnami/kafka/data \
  -v /usr/local/src/kafka/data:/bitnami/kafka/data \
  -p 9092:9092 \
  -p 9093:9093 \
  luode0320/kafka:latest
```

## 启动可视化工具

```sh
docker run -d \
  --name kafka-ui \
  --restart=always \
  -e DEFAULT_USERNAME=admin \
  -e DEFAULT_PASSWORD=admin \
  -v /usr/local/src/kafkaMap/data:/usr/local/kafka-map/data \
  -p 9091:8080 \
  luode0320/kafka-ui:latest
```

```
http://192.168.2.20:9091/
```



# 说明

```sh
-e KAFKA_CFG_NODE_ID=1 # 节点的 ID，这个 ID 在 Kafka 集群中必须是唯一的
-e KAFKA_CFG_PROCESS_ROLES=controller,broker # 节点既是控制器又是代理，负责集群的控制逻辑又负责消息的存储和转发
-e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.2.20:9092 # 外网IP的 9092 端口
-e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER # 控制器监听器的名称，这里设置为 CONTROLLER
-e KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 # 两个监听器
-e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT # 两个监听器使用明文传输协议
-e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@0.0.0.0:9093 # 选举投票者，使用 0.0.0.0 的 9093 端口
-e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv # Kafka Kraft 集群的 ID，用于标识属于同一个 Kraft 集群的 Kafka 节点
-e KAFKA_CFG_LOG_RETENTION_BYTES=5368709120 # 每个分区的日志大小，1G=1073741824, 5G=5368709120
-e KAFKA_CFG_LOG_SEGMENT_BYTES=104857600 # 每个分区每个分片日志的大小,100M=104857600

# 不删除日志
  -e KAFKA_CFG_LOG_RETENTION_BYTES=-1 \              # 禁用基于大小的清理
  -e KAFKA_CFG_LOG_RETENTION_HOURS=-1 \              # 禁用基于时间的清理
  -e KAFKA_CFG_LOG_SEGMENT_BYTES=104857600 \         # 日志段大小（100MB）
  -e KAFKA_CFG_LOG_CLEANER_ENABLE=false \            # 完全禁用日志清理器
```



# 修改配置

1. 更新容器的资源限制

```sh
docker update --restart=always kafka
```

2. 更新环境变量

```sh
docker rm -fv kafka
docker run -d \
  --restart=always \
  --name kafka \
  -e KAFKA_CFG_NODE_ID=1 \
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.2.20:9092 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@0.0.0.0:9093 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv \
  -e KAFKA_CFG_LOG_RETENTION_BYTES=5368709120 \
  -e KAFKA_CFG_LOG_SEGMENT_BYTES=536870912 \
  -e KAFKA_LOG_DIRS=/bitnami/kafka/data \
  -v /usr/local/src/kafka/data:/bitnami/kafka/data \
  -p 9092:9092 \
  -p 9093:9093 \
  luode0320/kafka:latest
```



# 命令

```sh
# 查询环境配置
docker exec kafka env | grep -E "KAFKA_CFG_LOG_RETENTION_BYTES|KAFKA_CFG_LOG_SEGMENT_BYTES"

# 查看所有分区
docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --all-groups --describe

# 消费者组的消费情况
docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group changelly-group --describe

# 重置到最早有效 OFFSET
docker exec kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group changelly-group \
  --reset-offsets \
  --to-earliest \
  --topic EXCHANGE_DATA_CCY_PAIR.SWFT:0,EXCHANGE_DATA_CCY_PAIR.ChangeNow:0,EXCHANGE_DATA_CCY_PAIR.Changelly:0 \
  --execute

# 或重置到最新 OFFSET（跳过积压消息）
docker exec kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group changelly-group \
  --reset-offsets \
  --to-latest \
  --topic EXCHANGE_DATA_CCY_PAIR.SWFT:0,EXCHANGE_DATA_CCY_PAIR.ChangeNow:0,EXCHANGE_DATA_CCY_PAIR.Changelly:0 \
  --execute

# 查询最早偏移量
docker exec kafka kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic EXCHANGE_DATA_CCY_PAIR.SWFT,EXCHANGE_DATA_CCY_PAIR.ChangeNow,EXCHANGE_DATA_CCY_PAIR.Changelly \
  --time -2 \
  --partitions 0
# 查询最新偏移量
docker exec kafka kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic EXCHANGE_DATA_CCY_PAIR.SWFT,EXCHANGE_DATA_CCY_PAIR.ChangeNow,EXCHANGE_DATA_CCY_PAIR.Changelly \
  --time -1 \
  --partitions 0
```

